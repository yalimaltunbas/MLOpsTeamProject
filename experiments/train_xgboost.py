# -*- coding: utf-8 -*-
"""train_xgboost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QX22iMn-D9dB9b9EnSWPMyv5LrpPq3TE
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

df = pd.read_csv("synthetic_medical_data.csv")  # datamÄ±z
df.head()

#Veri Temizleme PlanÄ±
from sklearn.model_selection import train_test_split
import pandas as pd

# 1ï¸âƒ£ SayÄ±sal sÃ¼tunlarÄ± median ile doldur
num_cols = df.select_dtypes(exclude='object').columns
df[num_cols] = df[num_cols].fillna(df[num_cols].median())

# 2ï¸âƒ£ Kategorik sÃ¼tunlarÄ± "Missing" ile doldur
cat_cols = df.select_dtypes(include='object').columns
df[cat_cols] = df[cat_cols].fillna("Missing")

# 3ï¸âƒ£ One-hot encoding (kategorik deÄŸiÅŸkenleri sayÄ±ya Ã§evir)
df_encoded = pd.get_dummies(df, drop_first=True)

# 4ï¸âƒ£ BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef (y)
X = df_encoded.drop("Dead", axis=1)
y = df_encoded["Dead"]

# 5ï¸âƒ£ Veriyi ayÄ±r
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("âœ… Train:", X_train.shape, " Test:", X_test.shape)
print("Ã–rnek sÄ±nÄ±f oranÄ±:", y.value_counts(normalize=True).round(3))

# 3- XGBOOST
!pip install xgboost
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

xgb = XGBClassifier(
    n_estimators=400,
    max_depth=5,
    learning_rate=0.05,
    scale_pos_weight=10,  # sÄ±nÄ±f dengesizliÄŸini telafi eder
    random_state=42
)

xgb.fit(X_train, y_train)
y_pred = xgb.predict(X_test)
y_proba = xgb.predict_proba(X_test)[:, 1]

print("ROC-AUC:", round(roc_auc_score(y_test, y_proba), 3))
print(classification_report(y_test, y_pred))

#XGBOOST ama eÅŸiÄŸi default 0.5den 0.4 e Ã§ektik
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# OlasÄ±lÄ±klarÄ± zaten aldÄ±k
y_proba = xgb.predict_proba(X_test)[:, 1]

# Burada eÅŸiÄŸi dÃ¼ÅŸÃ¼rÃ¼yoruz
threshold = 0.4
y_pred_custom = (y_proba >= threshold).astype(int)

print("ğŸ”¹ ROC-AUC (deÄŸiÅŸmez):", round(roc_auc_score(y_test, y_proba), 3))
print("\nğŸ”¹ SÄ±nÄ±flandÄ±rma Raporu (threshold = 0.3):\n", classification_report(y_test, y_pred_custom))
print("\nğŸ”¹ Confusion Matrix:\n", confusion_matrix(y_test, y_pred_custom))

#StratifiedKFold, XGBoost modeli Ã¼zerinde uygulandÄ±.
#Veriyi 5 parÃ§aya (foldâ€™a) ayÄ±rÄ±yor, her seferinde 4â€™Ã¼yle modeli eÄŸitiyor, 1â€™inde doÄŸruluyor. Bu iÅŸlem 5 kez tekrarlanÄ±yor ve sonuÃ§lar ortalanÄ±yor.
#Dengesiz veri setlerinde daha adil deÄŸerlendirme saÄŸlasÄ±n diye uyguluyoruz.
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
import numpy as np

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
aucs = []

for train_idx, val_idx in skf.split(X, y):
    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]

    model = XGBClassifier(
        n_estimators=400,
        max_depth=5,
        learning_rate=0.05,
        scale_pos_weight=10,
        random_state=42
    )
    model.fit(X_tr, y_tr)
    y_val_proba = model.predict_proba(X_val)[:, 1]
    aucs.append(roc_auc_score(y_val, y_val_proba))

print("Ortalama ROC-AUC:", np.mean(aucs), "Â±", np.std(aucs))


from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report,
    precision_recall_curve, average_precision_score, matthews_corrcoef
)
import numpy as np

def evaluate_clf(y_true, y_pred, y_proba):
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 3))
    print("Precision:", round(precision_score(y_true, y_pred, zero_division=0), 3))
    print("Recall:", round(recall_score(y_true, y_pred, zero_division=0), 3))
    print("F1-Score:", round(f1_score(y_true, y_pred, zero_division=0), 3))
    # ROC-AUC olasÄ±lÄ±k ister, sÄ±nÄ±f deÄŸil
    print("ROC-AUC:", round(roc_auc_score(y_true, y_proba), 3))
    # PR-AUC (hocanÄ±n istediÄŸi)
    pr_auc = average_precision_score(y_true, y_proba)
    print("PR-AUC:", round(pr_auc, 3))
    # MCC
    print("MCC:", round(matthews_corrcoef(y_true, y_pred), 3))
    print("\nClassification Report:\n", classification_report(y_true, y_pred, zero_division=0))
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))


y_proba = model.predict_proba(X_test)[:, 1]
y_pred = (y_proba >= 0.3).astype(int)   # ister 0.5, ister 0.3
evaluate_clf(y_test, y_pred, y_proba)

